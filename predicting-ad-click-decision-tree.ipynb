{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "n_rows = 300000\n",
    "df = pd.read_csv('ad-click.csv', nrows=n_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             id  click      hour    C1  banner_pos   site_id site_domain  \\\n",
      "0  1.000009e+18      0  14102100  1005           0  1fbe01fe    f3845767   \n",
      "1  1.000017e+19      0  14102100  1005           0  1fbe01fe    f3845767   \n",
      "2  1.000037e+19      0  14102100  1005           0  1fbe01fe    f3845767   \n",
      "3  1.000064e+19      0  14102100  1005           0  1fbe01fe    f3845767   \n",
      "4  1.000068e+19      0  14102100  1005           1  fe8cc448    9166c161   \n",
      "\n",
      "  site_category    app_id app_domain  ... device_type device_conn_type    C14  \\\n",
      "0      28905ebd  ecad2386   7801e8d9  ...           1                2  15706   \n",
      "1      28905ebd  ecad2386   7801e8d9  ...           1                0  15704   \n",
      "2      28905ebd  ecad2386   7801e8d9  ...           1                0  15704   \n",
      "3      28905ebd  ecad2386   7801e8d9  ...           1                0  15706   \n",
      "4      0569f928  ecad2386   7801e8d9  ...           1                0  18993   \n",
      "\n",
      "   C15  C16   C17  C18  C19     C20  C21  \n",
      "0  320   50  1722    0   35      -1   79  \n",
      "1  320   50  1722    0   35  100084   79  \n",
      "2  320   50  1722    0   35  100084   79  \n",
      "3  320   50  1722    0   35  100084   79  \n",
      "4  320   50  2161    0   35      -1  157  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 19) (300000,)\n"
     ]
    }
   ],
   "source": [
    "Y = df['click'].values\n",
    "X = df.drop(['click', 'id', 'hour', 'device_id', 'device_ip'], axis=1).values\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "# Samples are in chronological order, ordered by Hour\n",
    "# We cant use future samples to predict older ones\n",
    "\n",
    "n_train = int(n_rows*0.9)\n",
    "X_train, Y_train = X[:n_train], Y[:n_train]\n",
    "X_test, Y_test = X[n_train:], Y[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x8204 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 19 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform categorical features into one hot encoded vectors\n",
    "# news, education, sports -> is_news, is_education, is_sports\n",
    "# Handle unknown to prevent errors due to any unseen categorical values\n",
    "# e.g. if there is a sample with the value movie,\n",
    "# all of the three converted binary features (is_news, is_education, and is_sports)\n",
    "# become 0. If we do not specify ignore, an error will be raised.\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "X_train_enc = enc.fit_transform(X_train)\n",
    "X_train_enc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 188)\t1.0\n",
      "  (0, 2608)\t1.0\n",
      "  (0, 2679)\t1.0\n",
      "  (0, 3771)\t1.0\n",
      "  (0, 3885)\t1.0\n",
      "  (0, 3929)\t1.0\n",
      "  (0, 4879)\t1.0\n",
      "  (0, 7315)\t1.0\n",
      "  (0, 7319)\t1.0\n",
      "  (0, 7475)\t1.0\n",
      "  (0, 7824)\t1.0\n",
      "  (0, 7828)\t1.0\n",
      "  (0, 7869)\t1.0\n",
      "  (0, 7977)\t1.0\n",
      "  (0, 7982)\t1.0\n",
      "  (0, 8021)\t1.0\n",
      "  (0, 8189)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(X_train_enc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 8204)\n",
      "(270000, 8204)\n"
     ]
    }
   ],
   "source": [
    "X_test_enc = enc.transform(X_test)\n",
    "\n",
    "print(X_test_enc.shape)\n",
    "print(X_train_enc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "parameters = {'max_depth': [3, 10, None]}\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(criterion='gini', min_samples_split=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search = GridSearchCV(decision_tree, parameters, n_jobs=-1, cv=3, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(X_train_enc, Y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC on testing set is: 0.719\n"
     ]
    }
   ],
   "source": [
    "decision_tree_best = grid_search.best_estimator_\n",
    "pos_prob = decision_tree_best.predict_proba(X_test_enc)[:, 1]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(f\"The ROC AUC on testing set is: {roc_auc_score(Y_test, pos_prob):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC on testing set is 0.501\n"
     ]
    }
   ],
   "source": [
    "# Randomly selecting 17 % of samples instead will lower the accuracy\n",
    "import numpy as np\n",
    "pos_prob = np.zeros(len(Y_test))\n",
    "click_index = np.random.choice(len(Y_test), int(len(Y_test) * 51211.0/300000), replace=False)\n",
    "\n",
    "pos_prob[click_index] = 1\n",
    "\n",
    "print(f'The ROC AUC on testing set is {roc_auc_score(Y_test, pos_prob):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree is a sequence of greedy searches for the best splitting point at each step, based on training set\n",
    "# tends to cause overfitting\n",
    "# Ensembling is the technique to correct this\n",
    "# Random forest is an ensemble tree model that usually outperforms a simple decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble technique of bagging (bootstrap aggregating) can overcome overfitting\n",
    "# Different sets of training samples are randomly drawn with replacement from the original training data\n",
    "# Each set is used to fit an individual classification model\n",
    "# Results are combined together through majority vote to make final decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest is a variant of the tree bagging model with an additional of feature-based bagging\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100, criterion='gini', min_samples_split=30, n_jobs=-1)\n",
    "\n",
    "grid_search = GridSearchCV(random_forest, parameters, n_jobs=-1, cv=3, scoring='roc_auc')\n",
    "grid_search.fit(X_train_enc, Y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_best = grid_search.best_estimator_\n",
    "pos_prob = random_forest_best.predict_proba(X_test_enc)[:, 1]\n",
    "print(f'The ROC AUC on testing set is {roc_auc_score(Y_test, pos_prob):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critical hyperparameters:\n",
    "# 1. max_depth: deepest individual tree. It tends to overfit if too deep or underfit if too shallow\n",
    "# 2. min_samples_split: minimum number of split required for further splitting a node.\n",
    "# Too small cause overfitting, too large cause underfitting. 10, 30, 50 may be good to start with\n",
    "\n",
    "# Hyperparameters for forest / collection of trees\n",
    "# 1. max_features: number of features to consider for best splitting point search.\n",
    "# typically in an m-dimensional dataset, sqrt(m) is recommended value for max_features.\n",
    "# this can be specified as max_features='sqrt'\n",
    "# 2. n_estimators: number of trees considered for majority voting.\n",
    "# the more the trees, the better the performance, so is the computation time. 100, 200, 300 and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADIENT BOOSTED TREES\n",
    "# boosting, another ensemble technique\n",
    "# in boosted trees, individual trees are no longer trained separately\n",
    "# trees are trained in succession, where a tree aims to correct the errors made by the previous tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "Y_train_enc = le.fit_transform(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "model = xgb.XGBClassifier(learning_rate=0.1, max_depth = 10, n_estimators = 1000)\n",
    "\n",
    "model.fit(X_train_enc, Y_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_prob = model.predict_proba(X_test_enc)[:, 1]\n",
    "print(f'The ROC AUC on testing set is: {roc_auc_score(Y_test_enc, pos_proba):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
